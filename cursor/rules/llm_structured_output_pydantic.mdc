---
description:
globs:
alwaysApply: true
---
---
description: Rules for designing and utilizing Pydantic models as a unified framework for structured JSON output from Large Language Models (LLMs), ensuring consistency, reusability, and clear contracts.
globs: src/models/structured_output.py, src/inference/adapter.py, src/pipelines/components/**/*.py # Adjust globs as needed
alwaysApply: false # Auto Attached based on globs
agentRequested: false
---

**LLM Structured Output Framework with Pydantic: Core Principles**

This project employs a generalized framework for obtaining structured JSON output from LLMs using Pydantic models and a central `InferenceAdapter`. Adhere to the following principles:

1.  **Centralized Pydantic Schemas for LLM Outputs:**
    *   **Practice:** All Pydantic models representing structured data to be *generated by the LLM for internal consumption* **must** be defined in a designated central location (e.g., `src/models/structured_output.py`).
    *   This file is the single source of truth for LLM-generated data structures.
    *   Distinguish these internal LLM output schemas from Pydantic models used for external API request/response validation.

2.  **Pydantic Models as "LLM Output Contracts":**
    *   **Practice:** For any task where the LLM is expected to produce structured data, define a clear Pydantic `BaseModel` that precisely describes the desired fields, types, and constraints.
    *   These models serve as explicit contracts. The LLM (via tooling/function calling) is expected to return JSON conforming to the Pydantic model's schema.
    *   **Configuration:** Pydantic models for LLM output should typically use `model_config = ConfigDict(extra='forbid')` to strictly enforce the schema and reject unexpected fields from the LLM.

3.  **Reusable Nested Component Schemas:**
    *   **Practice:** Identify common, reusable data structures within LLM outputs (e.g., `CodeBlock`, `Table`, `Step`) and define them as separate Pydantic `BaseModel`s.
    *   Compose top-level LLM output schemas by nesting these reusable component schemas. This promotes DRY principles and consistency.

4.  **Generalized `InferenceAdapter` for Enforcement:**
    *   **Practice:** The `InferenceAdapter`'s primary LLM interaction method (e.g., `.chat()`) **must** be designed to accept any Pydantic `BaseModel` subclass as a `response_model` parameter.
    *   The adapter is responsible for:
        *   Converting the Pydantic model into the appropriate format for the LLM's tooling/function calling mechanism (e.g., JSON Schema).
        *   Making the API call to the LLM, instructing it to use the provided tool/function.
        *   Parsing the LLM's structured response.
        *   Validating the parsed response against the original `response_model`.
        *   Handling errors related to generation, parsing, or validation (e.g., raising `StructuredGenerationError`).

5.  **Components Specify Their Expected Output Schema:**
    *   **Practice:** Any component or service layer code that calls the `InferenceAdapter` to get structured output **must** explicitly pass the desired Pydantic model (imported from `src/models/structured_output.py`) as the `response_model` argument.
    *   Example: `inference_adapter.chat(..., response_model=ChatResponseContent)`

6.  **Separation of Concerns: Generation vs. Rendering:**
    *   **Practice:** The `InferenceAdapter` and the Pydantic schemas focus on *generating and validating* the structured data.
    *   Separate modules or functions should be responsible for *rendering* this structured data into user-facing formats (e.g., Slack messages, HTML). Rendering functions will be specific to the Pydantic schema they operate on (e.g., a function to render `ChatResponseContent` for Slack).

7.  **Standardized Error Handling:**
    *   **Practice:** Utilize custom, well-defined exceptions (e.g., `StructuredGenerationError`, `ApiCallError` defined in or near `src/models/structured_output.py`) to signal failures in the structured generation process. This allows for consistent error handling across components.

8.  **Optional Fields for LLM Flexibility:**
    *   **Practice:** Within top-level LLM output schemas (like `ChatResponseContent`), use `Optional` fields generously. The LLM should only populate the fields relevant to the specific query or task. The Pydantic model defines the *superset* of possible structured elements.

**Workflow for Adding New Structured LLM Output:**

1.  **Define Schema:** Create or update a Pydantic `BaseModel` in `src/models/structured_output.py` to represent the new structured data.
2.  **Update Component:** Modify the relevant component to call the `InferenceAdapter` (e.g., `.chat()`) method, passing the newly defined Pydantic model as the `response_model`.
3.  **Prompt Engineering (if needed):** Adjust the prompt sent to the LLM to guide it towards producing data that fits the new schema elements, especially if new concepts are introduced.
4.  **Update Rendering (if user-facing):** If this new structured data needs to be presented to a user, create or update a rendering function to format it appropriately.

This framework establishes a robust, schema-driven approach for all structured LLM communications, improving reliability and maintainability.
