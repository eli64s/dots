---
description:
globs:
alwaysApply: true
---
 Use type hints for all function signatures. Prefer Pydantic models over raw dictionaries for input validation. - Use Pydantic v2. - Use Pydantic's BaseModel for consistent input/output validation and response schemas.-   # Content: The actual instructions for the AI Agent  # Pydantic Best Practices for Structured LLM Output (GenAI Python Apps)  This rule provides guidance for designing and using Pydantic models within Python applications that leverage Language Models (LLMs) to produce structured data. Adhering to these practices will enhance the reliability, maintainability, and scalability of your GenAI applications.  **1. Fundamental Pydantic Usage (Pydantic v2)**  - **Standardization:** All data structures representing API contracts, LLM inputs/outputs, or structured content MUST be defined as Pydantic models inheriting from `pydantic.BaseModel`. - **Versioning:** Use Pydantic v2 (`pydantic>=2.0.0`). Leverage v2 features such as `model_validate`, `model_dump`, `model_json_schema`, `@field_validator`, `@model_validator`, and `ConfigDict`. - **Type Hinting:** Use standard Python type hints for all function/method signatures. For data structures, these SHOULD be the defined Pydantic models. - **Configuration:** Use `model_config = ConfigDict(...)` within your `BaseModel` subclasses for model-level configuration. Avoid the deprecated `Config` inner class. Refer to @`pydantic.config.ConfigDict` for available settings.  **2. Designing Structured LLM Output Schemas (`src/models/structured_output.py`)**  - **Explicit Contract:** Define Pydantic models that precisely represent the *desired JSON structure* you want the LLM to generate. - **Flexible Top-Level Schema:** Use a main model (e.g., `ChatResponseContent`) with optional fields (`Optional`) to accommodate various answer types (summary, steps, tables, code, etc.) within a single structure. The LLM should populate only the relevant fields. - **Granular Content Components:** Define separate `BaseModel` classes for distinct content types (e.g., `Table`, `CodeBlock`). Use these as types within your main structured output schema (e.g., `tables: Optional[List[Table]]`). This improves clarity and reusability. - **Clear Field Descriptions:** Every field in your structured output models MUST have a descriptive `description` argument in `pydantic.Field`. This is critical for generating good tool definitions that guide the LLM. - **Conciseness Constraints:** Use `pydantic.Field` arguments like `max_length` or `@field_validator` to enforce desired length constraints on text fields (e.g., for a summary). - **Completeness Flag:** Include a field like `is_complete: bool` if the LLM needs to indicate whether it could fully answer the query based on the context. - **Exclude Internal Fields:** Use `model_json_schema(exclude=['usage'])` or similar logic in the `InferenceAdapter` to prevent fields intended only for internal system use (like `usage`) from appearing in the tool definition schema sent to the LLM.  **3. Handling API Interaction Schemas (`src/inference/internal_api_schema.py`)**  - **Accurate Mapping:** Define Pydantic models that strictly mirror the JSON structure of the internal LLM API's request parameters (especially `tools`, `tool_prompt`, `tool_choice`) and response body (`Llama3InstructChatCompletionOutput`). - **Tool Definition Input:** When constructing the `tools` parameter for the API request, translate the Pydantic `response_model` schema into a JSON Schema object and place it in the `parameters` field of the function definition within the `tools` list. Assume `parameters` is the correct field for schema definition, aligning with standard practices and Llama documentation, despite potential ambiguities in API examples. - **Tool Call Output:** Define models (`Llama3InstructToolCall`, `Llama3InstructFunctionCall`) that match the API's response structure, specifically identifying where the generated JSON parameters (`arguments: str`) are located.  **4. Implementing Structured Output Logic (`src/inference/adapter.py`)**  - **Centralized Logic:** The `InferenceAdapter` (or a dedicated wrapper) is the sole component responsible for:     - Accepting the target `response_model` (Pydantic schema).     - Converting the `response_model` to the API's `tools` input format (Pydantic schema -> JSON Schema in `parameters`).     - Generating the `tool_prompt` and setting `tool_choice` to force the desired tool call.     - Making the API call.     - Processing the API response (`Llama3InstructChatCompletionOutput`).     - Extracting the JSON string from the tool call's `arguments` field.     - Using `response_model.model_validate_json(args_json_string)` for parsing and validation. - **Robust Error Handling:** Implement specific exception handling for API call failures (`ApiCallError`) and failures in obtaining/validating the structured output (`StructuredGenerationError`). Raise these errors for upstream handling. - **Handle Tool Call Failures:** Implement logic to detect when the LLM/API fails to return the expected tool call despite `tool_choice` and raise a `StructuredGenerationError`.  **5. Integrating Pydantic in Haystack Components**  - **Input/Output Typing:** Use Pydantic models in component method signatures and `@component.input_types`/`@component.output_types` decorators to clearly define the data flowing between components. - **LLM Calls:** Components that interact with the LLM for structured output (`ChatCompletion`, `QueryWriter`, `WorkflowDecisionGenerator`) MUST call the `InferenceAdapter.chat` method with the appropriate `response_model`. - **Process Structured Output:** Components receiving structured output from the Adapter/other components work directly with the validated Pydantic objects.  **6. Handling Validation and Serialization**  - **Validation:** Use `model_validate()` for Python dictionaries/objects and `model_validate_json()` for JSON strings. The `InferenceAdapter` handles this for LLM output; other components might use it for inputs. - **Serialization:** Use `model_dump()` to convert models to dictionaries (e.g., for logging, internal processing, building API request payloads). Use `model_dump_json()` for JSON strings (e.g., for final API responses where the body is a Pydantic model). - **Alias Usage:** Use `alias`, `validation_alias`, `serialization_alias`, and `alias_generator` as needed for mapping between internal field names and external JSON keys. Use `by_alias=True` or `serialize_by_alias=True` config when dumping for external use.  **7. Managing Errors and Retries**  - **Custom Exceptions:** Define a clear hierarchy of custom exceptions (e.g., inheriting from a base `StructuredOutputError`) for different failure types (API call, parsing, validation, no tool call). - **Upstream Handling:** Catch structured output errors (`StructuredGenerationError`) in orchestrating components like the `ConversationExecutor`. - **Retry Logic:** If implementing retries, modify the input messages/tool_prompt with details from the caught validation error (`pydantic.ValidationError.errors()`) before retrying the LLM call.  **8. Rendering Structured Output**  - **Separate Layer:** Implement a dedicated function or component to take the validated structured Pydantic object (`ChatResponseContent`) and format it into the final human-readable string (e.g., Markdown). This logic should check which optional fields are populated and format them accordingly. - **Helper Functions:** Create small helper functions for formatting specific complex components (e.g., `format_pydantic_table_to_markdown(table: Table)`).  **9. Preventing Prompt Leakage (Phrasing)**  - **Prompt Simplification:** Remove formatting instructions from core prompts. - **Workflow Control:** Handle scenarios like "no results found" via pipeline routing to predefined responses, bypassing LLM generation for these cases. - **Targeted Filtering:** Implement filtering logic (potentially within the rendering layer) to remove specific blacklisted conversational phrases from the text fields of the validated structured Pydantic object *after* generation but *before* final rendering.  **10. Maintainability and Extensibility**  - **Clear Structure:** Organize models logically in `**/models/` subdirectories (e.g., `models/inference/`, `models/api/`, `models/structured_output/`, `models/internal_api_schema/`). - **Documentation:** Provide clear docstrings for all models and fields. Use `description` in `Field` for LLM guidance. - **Versioning:** Consider versioning for structured output schemas (`ChatResponseContentV2`) if non-backward-compatible changes are necessary.  # Avoid Blacklisted Phrases (Applies to text fields within structured output)  When the LLM is generating text content for fields like `summary` or text within nested components, it must NOT use the following phrases:  - you can use the - there are examples for - i didnt find any - to help improve my search - i didnt find any related documents - i didnt find any related documents to your exact problem - that exist in the - should check the documentation - you can refer to the - an example of a - is an example of - additionally you can refer to the - to ensure that your - for more information on the - you have the following options - additionally you can refer - no you do not need - is an example of a
